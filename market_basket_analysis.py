# -*- coding: utf-8 -*-
"""Market Basket Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jD08xzvxwXSv7Z42X4KDI-i8nYhdwrux

#Association Rules
##Association rules are used to discover interesting relationships or patterns between items in large datasets. These rules are often used in Market Basket Analysis to identify products that frequently co-occur in transactions. An association rule is typically expressed in the form {ð´}â†’{ðµ}, meaning that if item ð´ is purchased, item ðµ is likely to be purchased as well.

#Source: Kaggle

https://www.kaggle.com/datasets/ahmtcnbs/datasets-for-appiori
"""

!pip install apyori #Installing apriori library

import numpy as np #NumPy is a powerful tool for numerical computations in Python.
import pandas as pd  #Pandas is a powerful library for data manipulation and analysis.
import seaborn as sns #Seaborn is a statistical data visualization library based on Matplotlib.
import matplotlib.pyplot as plt #Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.

df = pd.read_csv('basket_analysis.csv')

df.head() #Displays the first 5 rows of the dataset.

df.columns #Displays columns names of the dataset.

df.shape #Displays the total count of the Rows and Columns respectively.

df = df.drop('Unnamed: 0', axis=1)

df.shape #Displays the total count of the Rows and Columns respectively.

df.info() # Displays the total count of values present in the particular column along with the null count and data type.

df.isnull().sum() # Displays the total count of the null values in the particular columns.

"""As we can check there is no Null value in the dataset."""

from mlxtend.frequent_patterns import apriori, association_rules
apriori(df, min_support=0.15)[1:25]

df.mean() #The df.mean() function in pandas is used to calculate the mean (average) value of each column in a DataFrame.

"""Calculate Mean: For each numeric column in the DataFrame, it computes the mean value.

Return Result: It returns a pandas Series containing the mean values, with the column names as the index.
"""

# Compute frequent itemsets using the Apriori algorithm
frequent_itemsets = apriori(df,
                            min_support = .006,
                            max_len = 3,
                            use_colnames = True)

"""###Using the apriori function from the mlxtend library to perform Market Basket Analysis by finding frequent itemsets in the DataFrame df.

###min_support = 0.006: The minimum support threshold for the itemsets to be considered frequent. Support is the proportion of transactions that contain the itemset.

###max_len = 3: The maximum length (number of items) of the itemsets to be considered.

###use_colnames = True: This indicates that the column names should be used to represent items in the itemsets.
"""

frequent_itemsets

# Compute all association rules for frequent_itemsets
rules = association_rules(frequent_itemsets, #This is the input DataFrame containing the frequent itemsets that were previously generated using an algorithm like Apriori. Each row in this DataFrame typically includes an itemset and its corresponding support value.
                            metric = 'support', #This parameter specifies the metric used to evaluate the association rules. In this case, 'support' is chosen as the metric.
                            min_threshold=0.1) #This parameter sets the minimum threshold for the chosen metric. Only the rules that meet or exceed this threshold will be considered.

rules

"""###What the Code Does:

###Apply Multiple Filtering Conditions:


###The code applies all the specified filtering conditions to the rules DataFrame using the & (logical AND) operator. This ensures that only the rules meeting all the conditions are selected.


###Create a New DataFrame filtered_rules:

###The filtered rules are stored in a new DataFrame called filtered_rules.
"""

filtered_rules = rules[(rules['antecedent support'] > 0.02)& #This condition filters rules where the support for the antecedent itemset is greater than 0.02 (or 2% of all transactions).
                        (rules['consequent support'] >0.01) & #This condition filters rules where the support for the consequent itemset is greater than 0.01 (or 1% of all transactions).
                        (rules['confidence'] > 0.2)  #This condition filters rules where the confidence is greater than 0.2 (or 20%). Confidence measures the likelihood that the consequent is also present when the antecedent is present.
                        (rules['lift'] > 1.0)] #This condition filters rules where the lift is greater than 1. Lift greater than 1.0 (indicating a positive association).

"""Lift measures the strength of the association between the antecedent and the consequent. A lift value greater than 1 indicates that the antecedent and consequent occur together more frequently than would be expected if they were independent."""

filtered_rules

filtered_rules.sort_values('confidence',ascending=False)

"""###The filtered_rules.sort_values('confidence', ascending=False) code sorts the filtered association rules by the confidence metric in descending order. This allows you to easily identify the rules with the highest confidence, which can be interpreted as the most reliable or significant rules. Rules with higher confidence indicate a stronger association between the antecedent and consequent, making them more useful for decision-making and analysis."""

# Generate scatterplot confidence versus support
sns.scatterplot(x = "support", y = "confidence", data = filtered_rules)
plt.show()

"""###The purpose of this code is to filter the association rules in the rules DataFrame based on specified criteria for various metrics. This filtering process ensures that only the most significant and relevant association rules are retained for further analysis."""

filtered_rules = rules[(rules['antecedent support'] > 0.02)& #Purpose: To ensure that the rules include antecedent itemsets that appear in more than 2% of the transactions.
                        (rules['consequent support'] >0.01) & #Purpose: To ensure that the rules include consequent itemsets that appear in more than 1% of the transactions.
                        (rules['confidence'] > 0.45) &  #Purpose: To ensure that the rules have a confidence level greater than 0.45 (or 45%).
                        (rules['lift'] > 1.0)] #Purpose: To ensure that the rules have a lift greater than 1.

filtered_rules

# Generate scatterplot confidence versus support

sns.scatterplot(x = "support", y = "confidence", size= 'leverage',data = filtered_rules)
plt.legend(bbox_to_anchor= (1.02, 1), loc='upper left',)
plt.show()

# add extra another rule where support more than 0.2 for given itemset
filtered_rules = rules[(rules['antecedent support'] > 0.02)& #This ensures that the rules include antecedent itemsets that appear in more than 2% of the transactions.
                        (rules['consequent support'] >0.01) & #This ensures that the rules include consequent itemsets that appear in more than 1% of the transactions.
                        (rules['confidence'] > 0.45) & #This ensures that the rules have a confidence level greater than 0.45 (or 45%).
                        (rules['lift'] > 1.0)& #This ensures that the rules have a lift greater than 1.
                        (rules['support']>0.195)] #This ensures that the rules have a support value greater than 0.195 (or 19.5%).

filtered_rules

def rules_to_coordinates(rules): #rules_to_coordinates is a function that takes a DataFrame rules as input.
    rules['antecedent'] = rules['antecedents'].apply(lambda antecedent:list(antecedent)[0])
    #rules['antecedent']: This creates a new column in the DataFrame called 'antecedent'.
    #rules['antecedents']: This column contains sets of antecedents for each rule, such as {('milk',)}.
    #.apply(lambda antecedent: list(antecedent)[0]): This lambda function takes each set from the 'antecedents' column, converts it to a list, and extracts the first item from the list. It assumes that each antecedent set contains only one item.

    rules['consequent'] = rules['consequents'].apply(lambda consequent:list(consequent)[0])
    #rules['consequent']: This creates a new column in the DataFrame called 'consequent'.
    #rules['consequents']: This column contains sets of consequents for each rule, such as {('bread',)}.
    #.apply(lambda consequent: list(consequent)[0]): This lambda function extracts the first item from each consequent set, converting it to a single item.

    rules['rule'] = rules.index
    #rules['rule']: This creates a new column in the DataFrame called 'rule' that contains the index of each row.
    #rules.index: This refers to the index of the DataFrame, providing a unique identifier for each rule.

    return rules[['antecedent','consequent','rule']]
    #rules[['antecedent', 'consequent', 'rule']]: This returns a DataFrame with only the columns 'antecedent', 'consequent', and 'rule'.
    #This filtered DataFrame contains the essential information for each rule and is now ready for visualization or further processing.

from pandas.plotting import parallel_coordinates
# Convert rules into coordinates suitable for use in a parallel coordinates plot
coords = rules_to_coordinates(filtered_rules)
# Generate parallel coordinates plot
plt.figure(figsize=(3,6))
parallel_coordinates(coords, 'rule',colormap = 'ocean')
plt.legend([])
plt.show()

"""From the plot it seems like the butter can be used as cross-selling with other products, it also acts as something to be offered with antecedents that is low. Thus, the customers are more likely to buy them if the butter are offered with cheaper price if they buy the antecedents that sold less in a store"""